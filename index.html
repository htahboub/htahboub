<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Hamza Tahboub</title> <meta name="author" content="Hamza Tahboub"> <meta name="description" content=""> <meta name="keywords" content="hamza,tahboub,hamza tahboub,research,northeastern,personal"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://htahboub.github.io/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="https://github.com/HTahboub" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/hamzatahboub" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/hamza_tahboub" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/pfp-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/pfp-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/pfp-1400.webp"></source> <a href="https://www.strava.com/athletes/47831089" rel="external nofollow noopener" target="_blank"><img src="/assets/img/pfp.png" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="pfp.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></a> </picture> </figure> </div> <header class="post-header"> <h1 class="post-title"> Hamza Tahboub </h1> <p class="desc"><a href="https://neu.edu" rel="external nofollow noopener" target="_blank">Northeastern University</a>. Undergraduate.<br>tahboub.h [at] northeastern [dot] edu</p> </header> <article> <div class="clearfix"> <script>function checkTime(){isTimePassed=!0,document.getElementById("howard").style.display="block",document.getElementById("gaster").style.display="block"}var pattern=["ArrowUp","ArrowUp","ArrowDown","ArrowDown","ArrowLeft","ArrowRight","ArrowLeft","ArrowRight","b","a"],current=0,isTimePassed=!1,keyHandler=function(e){isTimePassed||pattern.indexOf(e.key)>=0&&e.key===pattern[current]?(current++,(pattern.length===current||isTimePassed)&&(current=0,document.getElementById("howard").style.display="block",document.getElementById("gaster").style.display="block")):current=0};document.addEventListener("keydown",keyHandler,!1),setTimeout(checkTime,1728e5);</script> <p><img style="display: none; position: fixed; right: 0; bottom: 35px;" id="howard" src="assets/img/howard.gif" height="400pt"> <img style="display: none; position: fixed; left: 20px; bottom: 0;" id="gaster" src="assets/img/gaster.gif" height="400pt"> Hello! My name is Hamza and I am a computer science &amp; math major at Northeastern University’s <a href="https://www.khoury.northeastern.edu/" rel="external nofollow noopener" target="_blank">Khoury College of Computer Sciences</a>.</p> <p>I am an undergraduate research assistant in Professor <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a>’s Visual Intelligence lab at Northeastern University. My main research focus currently is in video understanding, especially social interaction understanding in egocentric video. Also in the CS department, I worked as a teaching assistant for the <a href="https://course.ccs.neu.edu/cs2500/" rel="external nofollow noopener" target="_blank">Fundamentals of Computer Science</a> (CS 2500) course for a couple of semesters.</p> <style>.flex-container{display:flex;gap:10px;padding:5px 20px}.column{flex:1;padding-left:15px}@media(max-width:790px){.flex-container{flex-direction:column;gap:0}.column{padding-left:5px}.column:first-child ol{margin-bottom:0}}</style> <h4 style="margin-top: 25px;">Undergraduate Research Experience</h4> <div class="flex-container"> <div class="column"> <ol style="padding-left: 0px"> <li> <b>Unifying visual social interaction understanding</b> with Professors <a href="https://https://wyshi.github.io/" rel="external nofollow noopener" target="_blank">Weiyan Shi</a>, <a href="https://www.ganghua.org/" rel="external nofollow noopener" target="_blank">Gang Hua</a>, and <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>February 2025 – September 2025</li> <li><u>Paper currently under review.</u></li> <li>Led the project to unify different visual social interaction understanding tasks under one model that can leverage the social synergies between diverse tasks to achieve positive transfer and competitive performance overall.</li> <li>Also revealed that popular VLMs of the same scale suffer from a degradation that impairs their social understanding and leads to negative transfer.</li> </ul> </li> <li> <b>OneGaze</b> with <a href="https://www.linkedin.com/in/joseph-y-gu" rel="external nofollow noopener" target="_blank">Joseph Gu</a> and <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>June 2025 – Present</li> <li>Co-leading a project to develop an architecture that unifies two distinct gaze estimation tasks: image scanpath prediction and video saliency prediction.</li> <li>These tasks are closely related as they both ultimately model attention shifts while observing visual media.</li> </ul> </li> <li> <b>Egocentric Werewolf strategy classification and utterance prediction</b> with <a href="https://scholar.google.com/citations?user=n383kOYAAAAJ" rel="external nofollow noopener" target="_blank">Harrison Kim</a> and Professors <a href="https://https://wyshi.github.io/" rel="external nofollow noopener" target="_blank">Weiyan Shi</a> and <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>January 2024 – January 2025</li> <li>Led a project to understand subtle social cues from an egocentric perspective.</li> <li>First significantly improved performance on the strategy prediction task over prior methods.</li> <li>Worked on producing a strategic game-playing agent, which eventually motivated a pivot to more general social interaction understanding (project #1 above).</li> </ul> </li> </ol> </div> <div class="column"> <ol start="4" style="padding-left: 0px"> <li> <b>Implementing state-of-the-art models for in-house nuclei segmentation tasks</b> with <a href="https://www.linkedin.com/in/evanliu518/" rel="external nofollow noopener" target="_blank">Evan Liu</a> and <a href="https://scholar.google.com/citations?user=n383kOYAAAAJ" rel="external nofollow noopener" target="_blank">Harrison Kim</a> @ Genentech <ul> <li>October 2023 – December 2023</li> <li>Implemented state-of-the-art methods and contributed to novel approaches for nuclei semantic segmentation as part of the Genentech Computer Vision R&amp;D team.</li> </ul> </li> <li> <b>Medical QA fine-tuning</b> with <a href="https://scholar.google.com/citations?user=tIub9CgAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Dr. Michael Wu</a>, <a href="https://scholar.google.com/citations?user=FWcdgEwAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Chloe Kim</a>, and <a href="https://scholar.google.com/citations?user=7JbGx6UAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Ayush Zenith</a> @ Genentech <ul> <li>July 2023 – December 2023</li> <li>Fine-tuned ensembles of language models and NER/RE models on large-scale in-house medical datasets.</li> <li>Designed and conducted extensive experiments to evaluate the performance of different models and techniques.</li> </ul> </li> <li> <b>Long-form audio visual understanding</b> with <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>September 2023 – December 2023</li> <li>Conducted extensive literature review to scope future research directions.</li> <li> <a href="https://github.com/htahboub/pytorch-lfav" rel="external nofollow noopener" target="_blank">Re-implemented from scratch</a> the paper "<a href="https://arxiv.org/abs/2306.09431" rel="external nofollow noopener" target="_blank">Towards Long Form Audio-visual Video Understanding</a>" in PyTorch.</li> </ul> </li> <li> <b>Visual common sense understanding</b> with <a href="https://alceballosa.github.io/" rel="external nofollow noopener" target="_blank">Alberto Mario Ceballos Arroyo</a> and Professors <a href="https://www.byronwallace.com/" rel="external nofollow noopener" target="_blank">Byron Wallace</a> and <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>August 2022 – August 2023</li> <li>Focused first on visual question answering commonsense datasets and explored various approaches to solving the tasks.</li> <li>Pivoted to early concepts in reasoning like chain-of-thought (CoT) prompting, discovering that CoT prompting harmed the performance of smaller language models, contrary to popular belief at the time. We documented our findings in a <a href="assets/pdf/2023_preprint.pdf">preprint</a>.</li> </ul> </li> </ol> </div> </div> <p><br></p> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Hamza Tahboub. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: October 11, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-GFYR03EPD9"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-GFYR03EPD9");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>