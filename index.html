<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Hamza Tahboub</title> <meta name="author" content="Hamza Tahboub"> <meta name="description" content=""> <meta name="keywords" content="hamza,tahboub,hamza tahboub,research,northeastern,personal"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://htahboub.github.io/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <div class="navbar-brand social"> <a href="https://scholar.google.com/citations?user=aeId6qkAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/HTahboub" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/hamzatahboub" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/hamza_tahboub" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/pfp-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/pfp-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/pfp-1400.webp"></source> <a href="https://www.strava.com/athletes/47831089" rel="external nofollow noopener" target="_blank"><img src="/assets/img/pfp.png" class="img-fluid z-depth-1 rounded-circle" width="auto" height="auto" alt="pfp.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></a> </picture> </figure> </div> <header class="post-header"> <h1 class="post-title"> Hamza Tahboub </h1> <p class="desc"><a href="https://neu.edu" rel="external nofollow noopener" target="_blank">Northeastern University</a>. Undergraduate.<br>tahboub.h [at] northeastern [dot] edu</p> </header> <article> <div class="clearfix"> <script>function checkTime(){isTimePassed=!0,document.getElementById("howard").style.display="block",document.getElementById("gaster").style.display="block"}var pattern=["ArrowUp","ArrowUp","ArrowDown","ArrowDown","ArrowLeft","ArrowRight","ArrowLeft","ArrowRight","b","a"],current=0,isTimePassed=!1,keyHandler=function(e){isTimePassed||pattern.indexOf(e.key)>=0&&e.key===pattern[current]?(current++,(pattern.length===current||isTimePassed)&&(current=0,document.getElementById("howard").style.display="block",document.getElementById("gaster").style.display="block")):current=0};document.addEventListener("keydown",keyHandler,!1),setTimeout(checkTime,144e5);</script> <p><img style="display: none; position: fixed; right: 0; bottom: 35px;" id="howard" src="assets/img/howard.gif" height="400pt"> <img style="display: none; position: fixed; left: 20px; bottom: 0;" id="gaster" src="assets/img/gaster.gif" height="400pt"> Hello! My name is Hamza, and I am a computer science &amp; math major at Northeastern University’s <a href="https://www.khoury.northeastern.edu/" rel="external nofollow noopener" target="_blank">Khoury College of Computer Sciences</a>.</p> <p>I am a research assistant in Professor <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a>’s Visual Intelligence lab at Northeastern University. My research centers on multimodal learning, with a specific emphasis on social interaction understanding and egocentric video to holistically interpret human behavior. I am also interested in medical applications; I spent six months at Genentech’s R&amp;D department working on problems in computer vision and natural language processing in domains like nuclei segmentation and medical question answering.</p> <style>.flex-container{display:flex;gap:10px;padding:5px 20px}.column{flex:1;padding-left:15px}@media(max-width:790px){.flex-container{flex-direction:column;gap:0}.column{padding-left:5px}.column:first-child ol{margin-bottom:0}}</style> <h4 style="margin-top: 25px;">Undergraduate Research Experience</h4> <div class="flex-container"> <div class="column"> <ol style="padding-left: 0px"> <li> <b>Addressing social degradation in pre-trained vision-language models</b> with Professors <a href="https://wyshi.github.io/" rel="external nofollow noopener" target="_blank">Weiyan Shi</a>, <a href="https://www.ganghua.org/" rel="external nofollow noopener" target="_blank">Gang Hua</a>, and <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>February 2025 – Present</li> <li> <u style="color: #c00; font-weight: bold;">Accepted at TMLR.</u> <a href="https://arxiv.org/abs/2512.01148" rel="external nofollow noopener" target="_blank">[arxiv]</a> <a href="https://openreview.net/forum?id=ofYhEoKIEx" rel="external nofollow noopener" target="_blank">[openreview]</a> </li> <li>Led a project to unify different visual social interaction understanding tasks under one model, leveraging the synergies between diverse tasks to achieve positive transfer and competitive performance overall.</li> <li>Revealed popular VLMs of the same scale suffer a degradation impairing their social understanding and leading to negative transfer, which I uncovered comes from reduced social decodability of the visual representations after VLM training.</li> <li>Working on extending the work to handle complex compositional social tasks.</li> </ul> </li> <li> <b>OneGaze</b> with <a href="https://www.linkedin.com/in/joseph-y-gu" rel="external nofollow noopener" target="_blank">Joseph Gu</a> and <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>June 2025 – Present</li> <li>Co-leading a project to develop an architecture that unifies two distinct gaze estimation tasks: image scanpath prediction and video saliency prediction.</li> <li>These tasks are closely related as they both ultimately model how attention shifts while observing visual media.</li> </ul> </li> <li> <b>Egocentric Werewolf strategy classification and utterance prediction</b> with <a href="https://scholar.google.com/citations?user=n383kOYAAAAJ" rel="external nofollow noopener" target="_blank">Harrison Kim</a> and Professors <a href="https://wyshi.github.io/" rel="external nofollow noopener" target="_blank">Weiyan Shi</a> and <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>January 2024 – January 2025</li> <li>Led a project to understand subtle social cues from an egocentric perspective.</li> <li>Significantly improved performance in strategy prediction over prior methods.</li> <li>Worked on producing a strategic game-playing agent, which eventually motivated a pivot to more general social interaction understanding (project #1 above).</li> </ul> </li> </ol> </div> <div class="column"> <ol start="4" style="padding-left: 0px"> <li> <b>Modeling nuclei segmentation</b> with <a href="https://www.linkedin.com/in/evanliu518/" rel="external nofollow noopener" target="_blank">Evan Liu</a> and <a href="https://scholar.google.com/citations?user=n383kOYAAAAJ" rel="external nofollow noopener" target="_blank">Harrison Kim</a> @ <a href="https://www.gene.com/" rel="external nofollow noopener" target="_blank">Genentech gRED</a> <ul> <li>October 2023 – December 2023</li> <li>Contributed to novel approaches and implemented state-of-the-art methods for nuclei semantic segmentation as part of the Genentech Computer Vision R&amp;D team.</li> </ul> </li> <li> <b>Medical QA fine-tuning</b> with <a href="https://scholar.google.com/citations?user=tIub9CgAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Dr. Michael Wu</a>, <a href="https://scholar.google.com/citations?user=FWcdgEwAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Chloe Kim</a>, and <a href="https://scholar.google.com/citations?user=7JbGx6UAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Ayush Zenith</a> @ <a href="https://www.gene.com/" rel="external nofollow noopener" target="_blank">Genentech gRED</a> <ul> <li>July 2023 – December 2023</li> <li>Trained ensembles of language models and NER/RE models on large-scale in-house medical datasets.</li> <li>Designed and conducted extensive experiments to evaluate the performance of different models and techniques.</li> </ul> </li> <li> <b>Long-form audio-visual understanding</b> with <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>September 2023 – December 2023</li> <li>Conducted extensive literature review to scope future research directions.</li> <li> <a href="https://github.com/htahboub/pytorch-lfav" rel="external nofollow noopener" target="_blank">Re-implemented from scratch</a> papers like "<a href="https://arxiv.org/abs/2306.09431" rel="external nofollow noopener" target="_blank">Towards Long Form Audio-visual Video Understanding</a>" in PyTorch.</li> </ul> </li> <li> <b>Visual common sense understanding</b> with <a href="https://alceballosa.github.io/" rel="external nofollow noopener" target="_blank">Alberto Mario Ceballos Arroyo</a> and Professors <a href="https://www.byronwallace.com/" rel="external nofollow noopener" target="_blank">Byron Wallace</a> and <a href="https://jianghz.me/" rel="external nofollow noopener" target="_blank">Huaizu Jiang</a> <ul> <li>August 2022 – August 2023</li> <li>Focused first on visual question answering commonsense datasets and explored various approaches to solving the tasks.</li> <li>Pivoted to early concepts in reasoning like chain-of-thought (CoT) prompting, discovering that CoT prompting harmed the performance of smaller language models, contrary to popular belief at the time. We documented our findings in a <a href="assets/pdf/2023_preprint.pdf">preprint</a>.</li> </ul> </li> </ol> </div> </div> <p><br></p> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Hamza Tahboub. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: January 13, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-GFYR03EPD9"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-GFYR03EPD9");</script> </body> </html>